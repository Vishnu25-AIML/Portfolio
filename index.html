<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PORTFOLIO</title>
</head>
<body>
    <hr />
    <hr />
    <h1>M. Vishnu Vardhan Reddy</h1>
    <hr />
    <hr />
    <img src="./Photo.jpg" height="200" alt="Profile photo"/>
    <hr />
    <hr />
    <h2>PROFILE</h2>
        <p> Passionate Software Developer, eager to embark on a full-time role in Machine
            Learning or Data Science <br/>within an innovative company.I am committed to
            leveraging my programming expertise to drive the organization's success<br/> and
            advance cutting-edge technologies.</p>
    <hr />
    <hr />
    <h2>EDUCATION</h2>
    <ul>
        <li>
            <h3>10 th standard (Sri Chaithanya techno school)</h3>
            <p>2018-19 (Percentage: 91%)</p>
            
        </li>
        <li>
            <h3>12 th standard (Reva independent pu college)</h3>
            <p>2020-21 (Percentage: 94.5%)</p>
        </li>
        <li>
            <h3>B.E - AIML (BMS Institute of Technology & Management)</h3>
            <p>2021-25 (CGPA: 9.23)</p>
        </li>
    </ul>
    <hr />
    <hr />
    <h2>PROJECTS</h2>
        <ol>
            <li>
                <h3>SMART MAZE SOLVER USING REINFORCEMENT LEARNING</h3>
                <p>We developed a Q-learning-based system to train an agent to solve virtual mazes.<br/>
                    We then transferred the knowledge to a physical robot, enabling it to autonomously
                    navigate and solve real-world mazes.
                </p>
                <img src="./maze_solution.gif" height="180"/>
                <img src="./PMaze.gif" height="180"/>
            </li>
            <hr />
            <li><h3>LINE FOLLOWING ROBOT USING OPENCV AND RASPBERRY PI</h3>
                <p>Developed a Python program using OpenCV to help a robot navigate by detecting
                    path edges in video footage.<br /> Enhanced its navigation by programming color
                    recognition for red and green, enabling it to turn right and left.
                </p>
                <img src="./LFR.gif" height="180" width="140"/>
            </li>
            <hr />
            <li><h3>MINI VIRTUAL ASSISTANCE USING SIGN-LANGUAGE</h3>
                <p>Developed a virtual assistant using deep learning and computer vision for gesture
                    recognition. <br />Enabled web navigation, tab management, and custom operations
                    through sign language.<br/>Created a user-friendly interface with visual feedback for
                    sign and voice commands.                    
                </p>
                <img src="./MVA.gif" height="200"/>
            </li>
        </ol>
    <hr />
    <hr />
    <h2>INTERNSHIPS</h2>
        <ul>
            <li><h3>ROBOTICS</h3>
                <p>Comedkares Innovation Hub | Oct 2023 - Nov 2023<p>
            </li>
            <li><h3>MACHINE LEARNING</h3>
                <p>ZetaCoding Innovative Solutions | Ongoing<p>
            </li>
        </ul>
    <hr />
    <hr />
    <h2>SKILLS</h2>
        <ul>
            <li>C and C++</li>
            <li>Python Programming</li>
            <li>Machine Learning</li>
            <li>Deep Learning (Basic level)</li>
            <li>Internet of Things (Basic level)</li>
        </ul>
    <hr />        
    <hr />            
    
</body>
</html>